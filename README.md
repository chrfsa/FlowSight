# ğŸ¯ FlowSight - Extension de Tracing LangChain Local

Extension VSCode pour tracer et visualiser vos applications LangChain/LangGraph **localement**, sans dÃ©pendance cloud.

## ğŸš€ FonctionnalitÃ©s

- **Tracing Local**: Compatible API LangSmith (port 1984)
- **Visualisation Graph**: 3 stratÃ©gies automatiques
  1. ğŸŒ Fetch depuis API externe (port 8000)
  2. ğŸ“¦ Lecture depuis metadata
  3. ğŸ”§ Auto-gÃ©nÃ©ration depuis hiÃ©rarchie des runs
- **UI Moderne**: GitHub-style, dark theme, panels interactifs
- **Real-time**: Mise Ã  jour en temps rÃ©el pendant l'exÃ©cution

## ğŸ“¦ Installation

### 1. Installer l'extension dans VSCode

```bash
cd /home/said/Bureau/FlowSightProject
npm install
npm run compile
```

### 2. Lancer l'extension

1. Ouvrir le projet dans VSCode
2. Appuyer sur `F5` pour lancer en mode debug
3. Dans la fenÃªtre VSCode qui s'ouvre:
   - `Cmd+Shift+P` (ou `Ctrl+Shift+P`)
   - Taper "FlowSight: Open Monitor"

## ğŸ”Œ Configuration Python

### Configuration Simple (tracing uniquement)

```python
import os

# Active le tracing LangChain
os.environ["LANGCHAIN_TRACING_V2"] = "true"

# Redirige vers FlowSight local au lieu du cloud
os.environ["LANGCHAIN_ENDPOINT"] = "http://localhost:1984"

# Votre code LangChain habituel
from langchain_openai import ChatOpenAI
model = ChatOpenAI()
result = model.invoke("Hello!")
```

### Configuration avec Graph API (recommandÃ©)

Si vous avez un serveur LangGraph qui expose les endpoints:

```python
import os

# Tracing FlowSight
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_ENDPOINT"] = "http://localhost:1984"

# L'extension tentera de rÃ©cupÃ©rer le graph depuis:
# http://localhost:8000/api/v1/runs/{run_id}/graph
```

**Note**: Par dÃ©faut, FlowSight cherche l'API graph sur `http://localhost:8000`. Modifiable dans `extension.ts` ligne 236.

## ğŸ“Š Visualisation Graph

### Comment Ã§a marche

Quand vous cliquez sur le bouton **ğŸ“ˆ Graph**, FlowSight utilise une cascade de 3 stratÃ©gies:

#### 1ï¸âƒ£ **Fetch API** (PrioritÃ© Haute)
```
GET http://localhost:8000/api/v1/runs/{run_id}/graph

Response attendue:
{
  "nodes": [
    {"id": "node1", "name": "llm_call", "type": "llm"},
    {"id": "node2", "name": "review", "type": "chain"}
  ],
  "edges": [
    {"source": "node1", "target": "node2"}
  ]
}
```

#### 2ï¸âƒ£ **Metadata** (Fallback)
Si l'API n'est pas disponible, cherche dans les mÃ©tadonnÃ©es du run:
```python
from langgraph.graph import StateGraph
from langchain_core.runnables import RunnableConfig

graph = StateGraph(...)
compiled = graph.compile()

# GÃ©nÃ©rer le Mermaid
mermaid_graph = compiled.get_graph().draw_mermaid()

# Envoyer dans metadata
result = compiled.invoke(
    input_data,
    config=RunnableConfig(metadata={"mermaid_graph": mermaid_graph})
)
```

#### 3ï¸âƒ£ **Auto-gÃ©nÃ©ration** (Last Resort)
Si aucune des deux mÃ©thodes ne fonctionne, gÃ©nÃ¨re automatiquement un graph depuis la hiÃ©rarchie parent/enfant des runs tracÃ©s.

### Exemple visuel

```
ğŸŒ API disponible â†’ Graph riche avec conditional edges
ğŸ“¦ Metadata fournie â†’ Graph LangGraph natif
ğŸ”§ Auto-gen â†’ Graph simple (arbre des runs)
```

## ğŸ–¥ï¸ Interface Utilisateur

### Panels

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Runs       â”‚  Trace Tree      â”‚    Inspector           â”‚
â”‚  History    â”‚  (Waterfall)     â”‚                        â”‚
â”‚             â”‚                  â”‚  ğŸ“ˆ Graph  ğŸ“Š Stats    â”‚
â”‚  â€¢ Run 1    â”‚  ğŸ¤– LLM Call     â”‚                        â”‚
â”‚  â€¢ Run 2    â”‚    ğŸ”— Chain      â”‚  [DÃ©tails du span]     â”‚
â”‚  â€¢ Run 3    â”‚      âšª Tool     â”‚                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Boutons

- **ğŸ“ˆ Graph**: Affiche le graphe de workflow (en overlay)
- **ğŸ“Š Stats**: Toggle panneau statistiques (latence, tokens, timestamps)
- **Ã—**: Fermer l'inspector

## ğŸ§ª Test Rapide

```bash
# Lancer le test existant
python test_graph.py
```

VÃ©rifier dans VSCode FlowSight Monitor:
1. Un nouveau run apparaÃ®t dans "Runs History"
2. Cliquer dessus â†’ voir l'arbre d'exÃ©cution
3. Cliquer "ğŸ“ˆ Graph" â†’ voir le graphe auto-gÃ©nÃ©rÃ©

## ğŸ› ï¸ DÃ©veloppement

### Structure du projet

```
FlowSightProject/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ extension.ts    # Backend (Express) + Frontend (Webview)
â”œâ”€â”€ out/                # Compiled JS
â”œâ”€â”€ test_graph.py       # Script de test
â””â”€â”€ package.json
```

### Compiler aprÃ¨s modifications

```bash
npm run compile
# ou en mode watch
npm run watch
```

### Debugging

1. Console du webview: `Developer Tools` dans la fenÃªtre FlowSight
2. Logs serveur: Visible dans la console VSCode Debug

## ğŸ“ Endpoints ImplÃ©mentÃ©s

### FlowSight Server (Port 1984)
- `GET /info` - Info serveur
- `POST /runs` - CrÃ©er un run
- `PATCH /runs/:runId` - Mettre Ã  jour un run
- `POST /runs/batch` - OpÃ©rations batch

### API Graph Externe (Port 8000 - Optionnel)
- `GET /api/v1/runs/{run_id}/graph` - Structure du graph

## ğŸ¨ Personnalisation

### Changer le port API Graph

Dans `extension.ts` ligne 236:
```javascript
const GRAPH_API_ENDPOINT = 'http://localhost:8000';
```

### Modifier les styles Mermaid

Dans `convertAPIGraphToMermaid()` ligne 290:
```javascript
const nodeStyles = {
    'start': '([START])',
    'end': '([END])',
    'llm': '{{LLM}}',      // â† Formes des nodes
    'chain': '[CHAIN]',
    'tool': '[(TOOL)]',
};
```

## ğŸ› Troubleshooting

### Le graph ne s'affiche pas

1. **Ouvrir la console**: Clic droit dans FlowSight â†’ "Inspect Element"
2. **VÃ©rifier les logs**:
   - `âœ… Graph fetched from API` â†’ API OK
   - `âœ… Graph loaded from metadata` â†’ Metadata OK
   - `âš™ï¸ Auto-generating graph from runs...` â†’ Fallback actif
   - Erreur Mermaid? â†’ Syntaxe invalide

### "Graph API not available"

C'est normal si vous n'avez pas de serveur sur port 8000. L'extension utilisera automatiquement le fallback (metadata ou auto-gen).

### Pas de runs dans la sidebar

VÃ©rifier que:
```python
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_ENDPOINT"] = "http://localhost:1984"
```

## ğŸ”’ ConfidentialitÃ©

**100% local** - Aucune donnÃ©e n'est envoyÃ©e au cloud. Tous les runs restent sur votre machine.

## ğŸ“„ License

Projet open-source pour usage personnel et Ã©ducatif.

---

**Made with â¤ï¸ for local LangChain development**
